{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "*Task 1*"
      ],
      "metadata": {
        "id": "7xq2L_3u7MzA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "f4ueO3T364At",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a4d74a5-78f9-43ad-e692-0f883160ed7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shingling, signature generation, and LSH have been completed.\n",
            "Top similar documents to document 2 :\n",
            "   Document Index  Jaccard Similarity\n",
            "0               1             0.47619\n",
            "Approximate nearest neighbors for document 3 :\n",
            "Empty DataFrame\n",
            "Columns: [Document Index, Jaccard Similarity]\n",
            "Index: []\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from hashlib import sha256\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "class MinHashLSHFromDataFrame:\n",
        "    def __init__(self, dataframe, content_column, num_hash_functions=100):\n",
        "        self.dataframe = dataframe\n",
        "        self.content_column = content_column\n",
        "        self.num_hash_functions = num_hash_functions\n",
        "        self.hash_functions = [self._generate_hash_function(i) for i in range(num_hash_functions)]\n",
        "        self.signatures = None\n",
        "        self.buckets = None\n",
        "        self.shingling_result = None\n",
        "        self.shingle_mapping = {}\n",
        "        self.shingles_set = set()\n",
        "\n",
        "    def _generate_hash_function(self, seed):\n",
        "        def hash_function(x):\n",
        "            return int(sha256(f\"{seed}_{x}\".encode()).hexdigest(), 16)\n",
        "        return hash_function\n",
        "\n",
        "    def shingling(self, k=3):\n",
        "        if self.shingling_result is not None:\n",
        "            return self.shingling_result\n",
        "\n",
        "        rows, cols, data = [], [], []\n",
        "        for doc_idx, document in enumerate(self.dataframe[self.content_column]):\n",
        "            doc_shingles = set()\n",
        "            for i in range(len(document) - k + 1):\n",
        "                shingle = document[i:i+k]\n",
        "                if shingle not in self.shingle_mapping:\n",
        "                    self.shingle_mapping[shingle] = len(self.shingle_mapping)\n",
        "                if shingle not in doc_shingles:\n",
        "                    doc_shingles.add(shingle)\n",
        "                    shingle_idx = self.shingle_mapping[shingle]\n",
        "                    rows.append(doc_idx)\n",
        "                    cols.append(shingle_idx)\n",
        "                    data.append(1)\n",
        "        self.shingling_result = csr_matrix((data, (rows, cols)), shape=(len(self.dataframe), len(self.shingle_mapping)))\n",
        "        return self.shingling_result\n",
        "\n",
        "    def minhashing(self):\n",
        "        if self.signatures is not None:\n",
        "            return self.signatures\n",
        "\n",
        "        self.shingling()  # Ensure shingling is done first\n",
        "        num_docs, num_shingles = self.shingling_result.shape\n",
        "        signatures = np.full((num_docs, self.num_hash_functions), np.inf)\n",
        "        for doc_idx in range(num_docs):\n",
        "            doc_shingles = self.shingling_result[doc_idx].nonzero()[1]\n",
        "            for shingle_idx in doc_shingles:\n",
        "                hash_values = np.array([self.hash_functions[i](shingle_idx) for i in range(self.num_hash_functions)])\n",
        "                signatures[doc_idx] = np.minimum(signatures[doc_idx], hash_values)\n",
        "        self.signatures = pd.DataFrame(signatures)\n",
        "        return self.signatures\n",
        "\n",
        "    def locality_sensitivity_hashing(self, num_bands=20, rows_per_band=5):\n",
        "        if self.signatures is None:\n",
        "            self.minhashing()  # Ensure signatures are ready\n",
        "\n",
        "        assert self.signatures.shape[1] == num_bands * rows_per_band, \"Number of hash functions must equal num_bands * rows_per_band.\"\n",
        "        buckets = {}\n",
        "        num_rows = self.signatures.shape[0]\n",
        "        for band_index in range(num_bands):\n",
        "            start_index = band_index * rows_per_band\n",
        "            end_index = start_index + rows_per_band\n",
        "            for row_index in range(num_rows):\n",
        "                signature_slice = tuple(self.signatures.iloc[row_index, start_index:end_index])\n",
        "                bucket_id = hash((band_index, signature_slice))\n",
        "                if bucket_id in buckets:\n",
        "                    buckets[bucket_id].add(row_index)\n",
        "                else:\n",
        "                    buckets[bucket_id] = {row_index}\n",
        "        self.buckets = buckets\n",
        "        return self.buckets\n",
        "\n",
        "    def jaccard_similarity(self, doc1_idx, doc2_idx):\n",
        "        doc1_shingles = set(self.shingling_result[doc1_idx].nonzero()[1])\n",
        "        doc2_shingles = set(self.shingling_result[doc2_idx].nonzero()[1])\n",
        "        intersection = len(doc1_shingles & doc2_shingles)\n",
        "        union = len(doc1_shingles | doc2_shingles)\n",
        "        return intersection / union if union else 0\n",
        "\n",
        "    def jaccard_distance(self, doc1_idx, doc2_idx):\n",
        "        doc1_shingles = set(self.shingling_result[doc1_idx].nonzero()[1])\n",
        "        doc2_shingles = set(self.shingling_result[doc2_idx].nonzero()[1])\n",
        "        intersection = len(doc1_shingles & doc2_shingles)\n",
        "        union = len(doc1_shingles | doc2_shingles)\n",
        "        return 1 - (intersection / union) if union else 1\n",
        "\n",
        "    def find_top_similar_documents(self, doc_idx, n):\n",
        "        if self.shingling_result is None:\n",
        "            self.shingling()\n",
        "        num_docs = self.shingling_result.shape[0]\n",
        "        similarities = [(other_idx, self.jaccard_similarity(doc_idx, other_idx)) for other_idx in range(num_docs) if other_idx != doc_idx]\n",
        "        top_similarities = sorted(similarities, key=lambda x: x[1], reverse=True)[:n]\n",
        "        return pd.DataFrame(top_similarities, columns=[\"Document Index\", \"Jaccard Similarity\"])\n",
        "\n",
        "    def approx_nearest_neighbors(self, doc_idx, n):\n",
        "        if self.signatures is None:\n",
        "            self.minhashing()  # Ensure signatures are generated\n",
        "        doc_shingles = set(self.shingling_result[doc_idx].nonzero()[1])\n",
        "        doc_signature = np.array([min([self.hash_functions[i](shingle_idx) for shingle_idx in doc_shingles]) for i in range(self.num_hash_functions)])\n",
        "\n",
        "        candidates = set()\n",
        "        num_bands = self.signatures.shape[1] // 5\n",
        "        for band_index in range(num_bands):\n",
        "            start_index = band_index * 5\n",
        "            end_index = start_index + 5\n",
        "            band_signature = tuple(doc_signature[start_index:end_index])\n",
        "            bucket_id = hash((band_index, band_signature))\n",
        "            if bucket_id in self.buckets:\n",
        "                candidates.update(self.buckets[bucket_id])\n",
        "\n",
        "        similarities = [(other_idx, self.jaccard_similarity(doc_idx, other_idx)) for other_idx in candidates]\n",
        "        top_similarities = sorted(similarities, key=lambda x: x[1], reverse=True)[:n]\n",
        "        return pd.DataFrame(top_similarities, columns=[\"Document Index\", \"Jaccard Similarity\"])\n",
        "\n",
        "    def run(self):\n",
        "        self.shingling()\n",
        "        self.minhashing()\n",
        "        self.locality_sensitivity_hashing()\n",
        "        print(\"Shingling, signature generation, and LSH have been completed.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    df = pd.DataFrame({\n",
        "        'contents': [\n",
        "            \"/content/934.txt.\",\n",
        "            \"/content/2639.txt.\",\n",
        "        ]\n",
        "    })\n",
        "\n",
        "    lsh = MinHashLSHFromDataFrame(df, 'contents', num_hash_functions=100)\n",
        "    lsh.run()\n",
        "\n",
        "    # Find top similar documents to the first document\n",
        "    top_similarities = lsh.find_top_similar_documents(0, 3)\n",
        "    print(\"Top similar documents to document 2 :\")\n",
        "    print(top_similarities)\n",
        "\n",
        "    # Find approximate nearest neighbors for the first document\n",
        "    approx_neighbors = lsh.approx_nearest_neighbors(0, 3)\n",
        "    print(\"Approximate nearest neighbors for document 3 :\")\n",
        "    print(approx_neighbors)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/WebOfScience-5736.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "    file_content = file.readlines()\n",
        "\n",
        "print(\"Dòng 934:\", file_content[934])\n",
        "\n",
        "print(\"Dòng 2639:\", file_content[2639])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQG30EfJxhjp",
        "outputId": "dbe24e41-8ca9-4559-d658-fd2dcfd07d5f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dòng 934: Endonuclease cleavage is the rate-limiting step in the decay of nonsense-containing human beta-globin mRNA in erythroid cells. The 5'-truncated intermediates thus generated are polyadenylated and more stable than the parent mRNA. Northern blotting is commonly used to measure the decay rate of full-length mRNA, and S1 nuclease protection is used to assay the fate of decay intermediates. We have adapted the more sensitive and facile MBRACE assay (Lasham et al., Nucleic Acids Res 38: e19, 2010) to quantitatively monitor the decay process by detecting full-length beta-globin and its decay intermediates.\n",
            "\n",
            "Dòng 2639: Inferring beliefs and social emotions of others has different neural substrates and possibly different roles in the pathophysiology of different clinical phases of schizophrenia. The current study investigated the neural basis for inferring others' beliefs and social emotions, as individual concepts, in 17 subjects at ultra-high risk for psychosis (UHR), 16 patients with schizophrenia and 20 healthy controls. Brain activity significantly differed from normal in both the left superior temporal sulcus (STS) and the inferior frontal gyrus (IFG) in the schizophrenia group while inferring others' beliefs, whereas those of UHR group were in the middle of those in the schizophrenia and healthy-control groups. Brain activity during inferring others' social emotions significantly differed in both the left STS and right IFG among individuals at UHR; however, there was no significant difference in the schizophrenia group. In contrast, brain activity differed in the left IFG of those in both the schizophrenia and UHR groups while inferring social emotion. Regarding the difference in direction of the abnormality, both the UHR and schizophrenia groups were characterized by hyper-STS and hypo-IFG activations when inferring others' beliefs and emotions. These findings might reflect different aspects of the same pathophysiological process at different clinical phases of psychosis.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}