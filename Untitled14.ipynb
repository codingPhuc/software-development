{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "*Task 1*"
      ],
      "metadata": {
        "id": "7xq2L_3u7MzA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4ueO3T364At"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from hashlib import sha256\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "class MinHashLSHFromDataFrame:\n",
        "    def __init__(self, dataframe, content_column, num_hash_functions=100):\n",
        "        self.dataframe = dataframe\n",
        "        self.content_column = content_column\n",
        "        self.num_hash_functions = num_hash_functions\n",
        "        self.hash_functions = [self._generate_hash_function(i) for i in range(num_hash_functions)]\n",
        "        self.signatures = None\n",
        "        self.buckets = None\n",
        "        self.shingling_result = None\n",
        "        self.shingle_mapping = {}\n",
        "        self.shingles_set = set()\n",
        "\n",
        "    def _generate_hash_function(self, seed):\n",
        "        def hash_function(x):\n",
        "            return int(sha256(f\"{seed}_{x}\".encode()).hexdigest(), 16)\n",
        "        return hash_function\n",
        "\n",
        "    def shingling(self, k=3):\n",
        "        if self.shingling_result is not None:\n",
        "            return self.shingling_result\n",
        "\n",
        "        rows, cols, data = [], [], []\n",
        "        for doc_idx, document in enumerate(self.dataframe[self.content_column]):\n",
        "            doc_shingles = set()\n",
        "            for i in range(len(document) - k + 1):\n",
        "                shingle = document[i:i+k]\n",
        "                if shingle not in self.shingle_mapping:\n",
        "                    self.shingle_mapping[shingle] = len(self.shingle_mapping)\n",
        "                self.shingles_set.add(shingle)\n",
        "                if shingle not in doc_shingles:\n",
        "                    doc_shingles.add(shingle)\n",
        "                    shingle_idx = self.shingle_mapping[shingle]\n",
        "                    rows.append(doc_idx)\n",
        "                    cols.append(shingle_idx)\n",
        "                    data.append(1)\n",
        "\n",
        "        sparse_matrix = csr_matrix((data, (rows, cols)), shape=(len(self.dataframe), len(self.shingle_mapping)))\n",
        "        self.shingling_result = sparse_matrix\n",
        "        return self.shingling_result\n",
        "\n",
        "    def minhashing(self, bool_vectors):\n",
        "        if self.signatures is not None:\n",
        "            return self.signatures\n",
        "\n",
        "        num_docs, num_shingles = bool_vectors.shape\n",
        "        signatures = np.full((num_docs, self.num_hash_functions), np.inf)\n",
        "\n",
        "        for doc_idx in range(num_docs):\n",
        "            doc_shingles = bool_vectors[doc_idx].nonzero()[1]\n",
        "            for shingle_idx in doc_shingles:\n",
        "                hash_values = np.array([hash_func(shingle_idx) for hash_func in self.hash_functions])\n",
        "                signatures[doc_idx] = np.minimum(signatures[doc_idx], hash_values)\n",
        "\n",
        "        self.signatures = pd.DataFrame(signatures)\n",
        "        return self.signatures\n",
        "\n",
        "    def locality_sensitivity_hashing(self, signatures, num_bands=20, rows_per_band=5):\n",
        "        buckets = {}\n",
        "\n",
        "        num_rows, num_hash_functions = signatures.shape\n",
        "        assert num_hash_functions == num_bands * rows_per_band, \"The number of hash functions must equal the number of bands times the rows per band.\"\n",
        "\n",
        "        for band_index in range(num_bands):\n",
        "            for row_index in range(num_rows):\n",
        "                start_index = band_index * rows_per_band\n",
        "                end_index = start_index + rows_per_band\n",
        "                signature_slice = tuple(signatures.iloc[row_index, start_index:end_index])\n",
        "                bucket_id = hash((band_index, signature_slice))\n",
        "\n",
        "                if bucket_id in buckets:\n",
        "                    buckets[bucket_id].add(row_index)\n",
        "                else:\n",
        "                    buckets[bucket_id] = {row_index}\n",
        "\n",
        "        self.buckets = buckets\n",
        "        return self.buckets\n",
        "\n",
        "    def jaccard_similarity(self, doc1_idx, doc2_idx):\n",
        "        doc1_shingles = set(self.shingling_result[doc1_idx].nonzero()[1])\n",
        "        doc2_shingles = set(self.shingling_result[doc2_idx].nonzero()[1])\n",
        "        intersection = len(doc1_shingles & doc2_shingles)\n",
        "        union = len(doc1_shingles | doc2_shingles)\n",
        "        return intersection / union if union else 0\n",
        "\n",
        "    def find_top_similar_documents(self, doc_idx, n):\n",
        "        num_docs = self.shingling_result.shape[0]\n",
        "        similarities = [(other_idx, self.jaccard_similarity(doc_idx, other_idx)) for other_idx in range(num_docs) if other_idx != doc_idx]\n",
        "        top_similarities = sorted(similarities, key=lambda x: x[1], reverse=True)[:n]\n",
        "        return top_similarities\n",
        "\n",
        "    # Phương thức này tạo ra một bảng hiển thị `n` tài liệu tương tự nhất với tài liệu được chỉ định\n",
        "    # Bảng gồm có các cột: Document Index, Document String, Jaccard Similarity\n",
        "    def visualize_similarities(self, doc_idx, n):\n",
        "        top_similarities = self.find_top_similar_documents(doc_idx, n)\n",
        "        similarity_df = pd.DataFrame(top_similarities, columns=['Document Index', 'Jaccard Similarity'])\n",
        "        similarity_df['Document String'] = similarity_df['Document Index'].apply(lambda x: self.dataframe.iloc[x][self.content_column])\n",
        "        return similarity_df\n",
        "\n",
        "    # Phương thức này tìm kiếm các tài liệu tương tự với một tài liệu đã cho\n",
        "    # Sử dụng Locality Sensitive Hashing để tìm kiếm gần đúng\n",
        "    def approxNearestNeighbors(self, doc_idx, n):\n",
        "        doc_shingles = set(self.shingling_result[doc_idx].nonzero()[1])\n",
        "        doc_signature = np.array([min([self.hash_functions[i](shingle_idx) for shingle_idx in doc_shingles]) for i in range(self.num_hash_functions)])\n",
        "\n",
        "        candidates = set()\n",
        "        for band_index in range(len(self.signatures.columns) // 5):\n",
        "            start_index = band_index * 5\n",
        "            end_index = start_index + 5\n",
        "            band_signature = tuple(doc_signature[start_index:end_index])\n",
        "            bucket_id = hash((band_index, band_signature))\n",
        "\n",
        "            if bucket_id in self.buckets:\n",
        "                candidates.update(self.buckets[bucket_id])\n",
        "\n",
        "        similarities = [(other_idx, self.jaccard_similarity(doc_idx, other_idx)) for other_idx in candidates]\n",
        "        top_similarities = sorted(similarities, key=lambda x: x[1], reverse=True)[:n]\n",
        "        return top_similarities\n",
        "\n",
        "    def run(self):\n",
        "        self.shingling()\n",
        "        self.minhashing(self.shingling_result)\n",
        "        self.locality_sensitivity_hashing(self.signatures)\n",
        "        print(\"Shingling, signature generation, and LSH have been completed.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Example usage with DataFrame\n",
        "    df = pd.DataFrame({\n",
        "        'contents': [\n",
        "            \"WebOfScience-5736.txt.\",\n",
        "            \"Different species of Phytoplasmas infect different types of plants causing varied diseases.\"\n",
        "        ]\n",
        "    })\n",
        "    lsh = MinHashLSHFromDataFrame(df, 'contents', num_hash_functions=100)\n",
        "    lsh.run()\n",
        "\n",
        "    top_similarities = lsh.visualize_similarities(0, 5)\n",
        "    print(\"\\nTop similar documents to document 0:\")\n",
        "    print(top_similarities)\n",
        "\n",
        "    approx_neighbors = lsh.approxNearestNeighbors(0, 5)"
      ]
    }
  ]
}